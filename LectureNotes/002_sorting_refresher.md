---
marp: true
mermaid: true
theme: default
paginate: true
header: "Algorithms Refresher â€” Sorting Algorithms"
footer: "Algorithms Course"

---

# ğŸ§® Algorithms Refresher  
## Sorting Algorithms

**Insertion Sort Â· Merge Sort Â· QuickSort**

---

# ğŸ¯ Lesson Goals

- Refresh key sorting algorithms:
  - **Insertion Sort**
  - **Merge Sort**
  - **QuickSort**
- Understand:
  - Basic idea
  - Step-by-step process
  - Time complexity
  - When to use each

---

# ğŸ“¥ Insertion Sort â€” Idea

- Works like sorting playing cards in your hand.
- Builds the sorted list one element at a time.
- Each new element is **inserted** into its correct position in the already sorted portion.

---

# ğŸ§© Insertion Sort â€” Pseudocode

```text
for i = 1 to n-1:
    key = A[i]
    j = i - 1
    while j >= 0 and A[j] > key:
        A[j+1] = A[j]
        j = j - 1
    A[j+1] = key
```

---

# â±ï¸ Insertion Sort â€” Analysis

| Case | Comparisons | Time Complexity |
|------|--------------|----------------|
| Best (sorted input) | n-1 | **O(n)** |
| Average | ~nÂ²/4 | **O(nÂ²)** |
| Worst (reversed) | nÂ²/2 | **O(nÂ²)** |

âœ… Simple, adaptive, in-place.  
âŒ Slow for large datasets.

---

# âš™ï¸ Merge Sort â€” Idea

- **Divide and Conquer**:
  1. Divide the list into halves.
  2. Recursively sort each half.
  3. Merge the two sorted halves.

---

# ğŸ§© Merge Sort â€” Pseudocode

```text
merge_sort(A):
    if len(A) <= 1:
        return A
    mid = len(A) // 2
    left = merge_sort(A[:mid])
    right = merge_sort(A[mid:])
    return merge(left, right)
```

---

# â±ï¸ Merge Sort â€” Analysis

| Case | Time Complexity | Space |
|------|------------------|--------|
| Best | O(n log n) | O(n) |
| Average | O(n log n) | O(n) |
| Worst | O(n log n) | O(n) |

âœ… Guaranteed O(n log n).  
âŒ Requires extra space.  
ğŸ“¦ Stable and predictable.

---

# âš¡ QuickSort â€” Idea

- Also **Divide and Conquer**, but smarter splitting:
  1. Choose a **pivot**.
  2. Partition array into:
     - smaller than pivot
     - pivot
     - larger than pivot
  3. Recursively sort the partitions.

---

# ğŸ§© QuickSort â€” Pseudocode

```text
quick_sort(A, low, high):
    if low < high:
        p = partition(A, low, high)
        quick_sort(A, low, p-1)
        quick_sort(A, p+1, high)
```

---

# â±ï¸ QuickSort â€” Analysis

| Case | Time Complexity | Notes |
|------|------------------|--------|
| Best | O(n log n) | balanced splits |
| Average | O(n log n) | expected |
| Worst | O(nÂ²) | unbalanced (e.g. sorted input with bad pivot) |

âœ… Fast in practice, in-place.  
âŒ Unstable; needs good pivot strategy.

---

# ğŸ¯ Summary â€” Sorting Algorithms

| Algorithm | Best | Average | Worst | Stable | In-place |
|------------|-------|----------|--------|----------|-----------|
| Insertion | O(n) | O(nÂ²) | O(nÂ²) | âœ… | âœ… |
| Merge | O(n log n) | O(n log n) | O(n log n) | âœ… | âŒ |
| Quick | O(n log n) | O(n log n) | O(nÂ²) | âŒ | âœ… |

---


# ğŸ§  Key Takeaways

- **Insertion Sort** â€” simple, good for small or nearly sorted data.  
- **Merge Sort** â€” consistent, stable, predictable.  
- **QuickSort** â€” usually fastest, in-place.

---

# ğŸ§© Exercises â€” Conceptual

1. What makes Merge Sortâ€™s time complexity always O(n log n)?  
2. Why does QuickSortâ€™s performance degrade for already sorted input?  
3. For small arrays (n < 10), which algorithm would you use and why?  
4. Which algorithm is stable, and why does stability matter?  

---

# ğŸ§® Exercises â€” Practical

### 1. Trace Insertion Sort on:
`[8, 3, 5, 4, 6]`  
Show each step of the insertion.

### 2. Trace Merge Sort on:
`[7, 2, 9, 4]`  
Show the recursive splits and merges.

### 3. QuickSort Partitioning
Given `[4, 9, 2, 6, 1, 5]` and pivot = 4,  
show the partitioned array after one partition step.

---

# ğŸ End of Lesson

âœ… Reviewed: Insertion, Merge, QuickSort  
ğŸ§© Practiced: tracing and analysis  
ğŸ“˜ Next: **Lower bounds of sorting** and **non-comparison sorts**.

---
